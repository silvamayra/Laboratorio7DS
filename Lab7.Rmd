---
title: "Laboratorio 7"
author: "Grupo 10"
date: "9/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librerías a utilizar

```{r cars}
#Instalación de paquetes neuevos
if(!require(twitteR)) {install.packages("twitteR")}
if(!require(ROAuth)) {install.packages("ROAuth")}
if(!require(readr)) {install.packages("readr")}
if(!require(tm)) {install.packages("tm")}
if(!require(wordcloud)) {install.packages("wordcloud")}
if(!require(ggplot2)) {install.packages("ggplot2")}
if(!require(base64enc)) {install.packages("base64enc")}
if(!require(openssl)) {install.packages("openssl")}
if(!require(httpuv)) {install.packages("httpuv")}
if(!require(httr)) {install.packages("httr")}

library("twitteR")
library("ROAuth")
library("readr") #Lee los archivos 
library("tm")  #Contiene tranformaciones para el text mining
library("wordcloud")
library(ggplot2) #para gráficos
library(base64enc)
library(openssl)
library(httpuv)
library(httr)
library("SentimentAnalysis")
library("SnowballC") #Para sentiment analysis
library(tidytext) #otra para análisis de sentimientos.
library("syuzhet")
library(dplyr) 
library(plyr)


```

# Obteniendo el acceso a Twitter
Para la realización de este laboratorio se decidió utilizar Twitter, para ello se creó una APP desde la página para developers de Twitter, donde se debía de obtener la autorización de Twitter para poder tener una APP de developer. Luego, con la autorización fue posible obtener el API y el token para poder obtener los tweets.

```{r pressure, echo=FALSE}
options(httr_oauth_cache=T)
my.consumer.key <- "MqlOqVvLnJb5o1xGs0o5Hu23Z"
my.consumer.secret <- "eNM9IVRcuRNihtJK9glzMOoebFhxrm25z5IpUjGdffrWAz6nQi"
my.access.token <- "225578097-aDwImEKkCOhVRF6aWwz4KDRsF7VuGi4qn5df7kdk"
my.access.token.secret <- "5dv2mv7v059gIlMxbKfHpvXtqo5WpwrjfJI4lJXXmFi86"
my_oauth <- setup_twitter_oauth(consumer_key = my.consumer.key, consumer_secret = my.consumer.secret, access_token = my.access.token, access_secret = my.access.token.secret)
save(my_oauth, file = "my_oauth.Rdata")
```

#Obtención de los datos para el Hashtag TráficoGT
Se utilizaron las librerías *TwitterR* y *ROAuth* para la obtención de los datos y análisis. Se tomó la decisión de utilizar el $#TraficoGt$, con ayuda de las librerias importadas se buscaron los tweets y se creó un data frame a partir de los resultados obtenidos. 
```{r pressure, echo=FALSE}
search.string <- "#TraficoGT"
result.term <- searchTwitter(search.string, n = 1000)
head(result.term)

#Se almacena todo en un Data Frame
```
```{r}
dataTweets<- twListToDF(result.term)
write.csv(dataTweets, "tweets.csv")
tweets.text <- sapply(result.term, function(x) x$getText())
```


# Limpieza y preprocesamiento

```{r}
# Quitar (“rt”)
tweets.text <- gsub("rt", "", tweets.text)
# Quitar @Usuario
tweets.text <- gsub("@\\w+", "", tweets.text)
# Quitar #Hashtag
tweets.text <- gsub("#\\S+", "", tweets.text)
# Quitar puntuaciones
tweets.text <- gsub("[[:punct:]]", "", tweets.text)
# Quitar links
tweets.text <- gsub("http\\w+", "", tweets.text)
# Quitar tabs
tweets.text <- gsub("[ |\t]{2,}", "", tweets.text)
# Quitar espacios en blanco del principio
tweets.text <- gsub("^ ", "", tweets.text)
# Quitar espacios en blanco del final
tweets.text <- gsub(" $", "", tweets.text)
# Convertir a minúsculas
tweets.text <- tolower(tweets.text)
# Cambio de tildes
tweets.text <- gsub("á", "a", tweets.text)
tweets.text <- gsub("é", "e", tweets.text)
tweets.text <- gsub("í", "i", tweets.text)
tweets.text <- gsub("ó", "o", tweets.text)
tweets.text <- gsub("ú", "u", tweets.text)
```

```{r}
if(!require(tm)) {install.packages("tm")}
library(tm)
#create corpus
#clean up by removing stop words
tweets.corpus <- Corpus(VectorSource(tweets.text))
tweets.corpus <- tm_map(tweets.corpus, content_transformer(removeNumbers))
tweets.corpus <- tm_map(tweets.corpus, function(x) removeWords(x,stopwords("spanish")))
```


# Análisis exploratorio

## Nube de palabras
```{r}
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
```

## Histograma de palabras con más frecuencia
```{r}
dtm <- DocumentTermMatrix(tweets.corpus)

freq <- colSums(as.matrix(dtm))

wfTweet <- data.frame(word = names(freq), freq = freq)
head(wfTweet)


HistoR <- ggplot(subset(wfTweet, freq>100), aes(x = reorder(word, -freq), y = freq)) +
          geom_bar(stat = "identity") + ggtitle("Palabras más frecuentes") +
          theme(axis.text.x=element_text(angle=45, hjust=1))
HistoR

```

## Histograma de palabras con menos frecuencia
```{r}
freqWords <- apply(dtm,2,sum)
freqData <- data.frame(word=names(freqWords), frecuency=as.numeric(freqWords), stringsAsFactors = FALSE)
freqData<- freqData[order(freqData$frecuency, decreasing=TRUE), ]
barplot(tail(freqData$frecuency, n = 20), names.arg = tail(freqData$word, n = 20), main = "Palabras menos frecuentes", ylab = "Freq")

```

## Asociasión de palabras
Según las palabras más frecuentes, se encontró la palabra 'zona', vamos a indagar que palabras se encuentran asociadas a esta con el fin de poder determinar algún tipo de relación.

```{r}

findAssocs(dtm, 'zona', 0.2)
```

```{r}

findAssocs(dtm, 'avenida', 0.2)

```
Vemos que la palabra "avenida" se relaciona  con advertencias o incidentes tipo "volcado", "precaucion" y lugares como "montufar", "verbena", "chinautla" y nos llama la atención la palabra "manifestaciongt". 
```{r}
findAssocs(dtm, 'ruta', 0.2)
```

También decidimos analizar la palabra "ruta", la palabra que presenta mayor correlación es la de "atlántico", lo cual nos lleva a cuestionarnos: ¿acaso se realizan mayor cantidad de reportes de tránsito sobre la Ruta al Atlántico.

Así también vemos que se relaciona bastante con otras carreteras como la Interamericanta, Pacífico y Salvador. Otro hecho que nos llama la atención es su relación con las palabras "bloquean", "entrada" y "manifestantes" lo cual nos lleva a inferir que también se reportan con mayor frecuencia los bloqueos que realizan los manifestantes.


## Analizando los retweets
 Para ello, se creó un data frame que contuviera solamente el texto y la frecuencia de Retweets que obtuvo, a partir de el con la función *order* se colocaron en orden descendente y se mostrarán los primeros 10.
```{r}
txandrt <- dataTweets[c(1,12)]
rt<-txandrt[order(txandrt$retweetCount, decreasing = TRUE),] 
rtMost <-rt[!duplicated(rt),]
head(rtMost,10)
```

Observamos que la mayoría son retweets de ConsejoMontejo y que contienen la palabra "UrgenteGt"


## Análisis de sentimientos
```{r}
senti.tweets <-get_nrc_sentiment(as.vector(dataTweets$text))
# Total de cada sentimiento
Sentimentscores <-data.frame(colSums(senti.tweets[,]))

names(Sentimentscores)<-"Puntaje"
Sentimentscores <-cbind("Sentimiento"=rownames(Sentimentscores),Sentimentscores)
rownames(Sentimentscores)<-NULL

# Se grafica los puntajes de cada sentimiento
ggplot(data=Sentimentscores,aes(x=Sentimiento,y=Puntaje))+geom_bar(aes(fill=Sentimiento),stat = "identity")+
  theme(legend.position="none")+
  xlab("Sentimiento")+ylab("Puntaje")+ggtitle("Sentimientos de las personas con tweets acerca del tráfico en Guatemala")
```




