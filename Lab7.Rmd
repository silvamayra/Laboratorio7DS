---
title: "Laboratorio 7"
author: "Grupo 10"
date: "9/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librerías a utilizar

```{r cars}
#Instalación de paquetes neuevos
#install.packages("twitteR")
#install.packages("ROAuth")
library("twitteR")
library("ROAuth")
library("readr") #Lee los archivos 
library("tm")  #Contiene tranformaciones para el text mining
library("wordcloud")
library(ggplot2) #para gráficos
library(base64enc)
library(openssl)
library(httpuv)
library(httr)

```

# Obteniendo el acceso a Twitter
Para la realización de este laboratorio se decidió utilizar Twitter, para ello se creó una APP desde la página para developers de Twitter, donde se debía de obtener la autorización de Twitter para poder tener una APP de developer. Luego, con la autorización fue posible obtener el API y el token para poder obtener los tweets.

```{r pressure, echo=FALSE}
options(httr_oauth_cache=T)
my.consumer.key <- "MqlOqVvLnJb5o1xGs0o5Hu23Z"
my.consumer.secret <- "eNM9IVRcuRNihtJK9glzMOoebFhxrm25z5IpUjGdffrWAz6nQi"
my.access.token <- "225578097-aDwImEKkCOhVRF6aWwz4KDRsF7VuGi4qn5df7kdk"
my.access.token.secret <- "5dv2mv7v059gIlMxbKfHpvXtqo5WpwrjfJI4lJXXmFi86"
my_oauth <- setup_twitter_oauth(consumer_key = my.consumer.key, consumer_secret = my.consumer.secret, access_token = my.access.token, access_secret = my.access.token.secret)
save(my_oauth, file = "my_oauth.Rdata")
```

#Obtención de los datos para el Hashtag TráficoGT
Se utilizaron las librerías *TwitterR* y *ROAuth* para la obtención de los datos y análisis. Se tomó la decisión de utilizar el $#TraficoGt$, con ayuda de las librerias importadas se buscaron los tweets y se creó un data frame a partir de los resultados obtenidos. 
```{r pressure, echo=FALSE}
search.string <- "#TraficoGT"
result.term <- searchTwitter(search.string, n = 1000)
head(result.term)

#Se almacena todo en un Data Frame
```
```{r}
dataTweets<- twListToDF(result.term)
write.csv(dataTweets, "tweets.csv")
tweets.text <- sapply(result.term, function(x) x$getText())
```


# Limpieza y preprocesamiento

```{r}
# Quitar (“rt”)
tweets.text <- gsub("rt", "", tweets.text)
# Quitar @Usuario
tweets.text <- gsub("@\\w+", "", tweets.text)
# Quitar puntuaciones
tweets.text <- gsub("[[:punct:]]", "", tweets.text)
# Quitar links
tweets.text <- gsub("http\\w+", "", tweets.text)
# Quitar tabs
tweets.text <- gsub("[ |\t]{2,}", "", tweets.text)
# Quitar espacios en blanco del principio
tweets.text <- gsub("^ ", "", tweets.text)
# Quitar espacios en blanco del final
tweets.text <- gsub(" $", "", tweets.text)
# Convertir a minúsculas
tweets.text <- tolower(tweets.text)
# Quitar #Hashtag
tweets.text <- gsub("#\\S+", "", tweets.text)
# Cambio de tildes
tweets.text <- gsub("á", "a", tweets.text)
tweets.text <- gsub("é", "e", tweets.text)
tweets.text <- gsub("í", "i", tweets.text)
tweets.text <- gsub("ó", "o", tweets.text)
tweets.text <- gsub("ú", "u", tweets.text)
```

```{r}
if(!require(tm)) {install.packages("tm")}
library(tm)
#create corpus
#clean up by removing stop words
tweets.corpus <- Corpus(VectorSource(tweets.text))
tweets.corpus <- tm_map(tweets.corpus, content_transformer(removeNumbers))
tweets.corpus <- tm_map(tweets.corpus, function(x) removeWords(x,stopwords("spanish")))
```


# Análisis exploratorio

## Nube de palabras
```{r}
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
```

## Histograma de palabras con más frecuencia
```{r}
dtm <- DocumentTermMatrix(tweets.corpus)

freq <- colSums(as.matrix(dtm))

wfTweet <- data.frame(word = names(freq), freq = freq)
head(wfTweet)


HistoR <- ggplot(subset(wfTweet, freq>100), aes(x = reorder(word, -freq), y = freq)) +
          geom_bar(stat = "identity") + ggtitle("Palabras más frecuentes") +
          theme(axis.text.x=element_text(angle=45, hjust=1))
HistoR

```

## Histograma de palabras con menos frecuencia
```{r}
freqWords <- apply(dtm,2,sum)
freqData <- data.frame(word=names(freqWords), frecuency=as.numeric(freqWords), stringsAsFactors = FALSE)
freqData<- freqData[order(freqData$frecuency, decreasing=TRUE), ]
barplot(tail(freqData$frecuency, n = 20), names.arg = tail(freqData$word, n = 20), main = "Palabras menos frecuentes", ylab = "Freq")

```

#Análisis y descubrimientos

Según las palabras más frecuentes, se encontró la palabra 'placa', vamos a indagar que palabras se encuentran asociadas a esta con el fin de poder determinar algún tipo de relación.

```{r}

findAssocs(dtm, 'placa', 0.2)
```

Lo que nos llama la atención es que se relaciona con el apellido "Hernández" y "Charly". Vamos a explorar con que palabras se relacionan: 
```{r}

findAssocs(dtm, 'charly', 0.2)
```
Vemos que la palabra "Charly" se relaciona con palabras similares que las de "placa".
```{r}
findAssocs(dtm, 'hernández', 0.2)
```

Para el caso de Hernández obtuvimos un resultado inesperado, resulta que no posee un valor de correlación mayor a 0.2 en todo el documento con las demás palabras, concluimos que a pesar de estar en las palabras más frecuentes no se relacioa mucho con las otras palabras. 

